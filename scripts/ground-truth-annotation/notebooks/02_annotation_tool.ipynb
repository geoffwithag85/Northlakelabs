{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Ground Truth Annotation Tool\n",
    "\n",
    "This notebook provides an interactive interface for manually annotating gait events in the T5 constrained gait trial.\n",
    "\n",
    "## Objective\n",
    "- Create sensor-independent ground truth for algorithm validation\n",
    "- Manually annotate heel strike and toe off events for both legs\n",
    "- Export annotations for algorithm comparison\n",
    "\n",
    "## Annotation Methodology\n",
    "- **Expert-based**: Manual annotation by biomechanics expert\n",
    "- **Multi-modal**: Using force, kinematic, and EMG data simultaneously\n",
    "- **Constraint-aware**: Accounting for left leg locked extension compensation patterns\n",
    "- **Sensor-independent**: Not dependent on any single sensor threshold"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Setup and imports\nimport sys\nsys.path.append('../src')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display, clear_output\nimport ipywidgets as widgets\n\nfrom data_loader import GaitDataLoader\n\n# Configure plotting\nplt.style.use('default')\nplt.rcParams['figure.figsize'] = (15, 8)\nplt.rcParams['font.size'] = 10\n\nprint(\"Interactive annotation environment ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Load T5 trial data for annotation\nloader = GaitDataLoader(data_dir=\"../data\")\ntrial_id = \"T5\"\n\n# Load the data\nkinetics_data = loader.load_kinetics(trial_id)\nemg_data = loader.load_emg(trial_id)\nkinematics_data = loader.load_kinematics(trial_id)\n\n# Create 20-second analysis window (consistent with demo)\ntime_window = 20.0\nkinetics_window = kinetics_data[kinetics_data['time'] <= time_window].copy()\n\nprint(f\"Data loaded for manual annotation:\")\nprint(f\"Trial: {trial_id}\")\nprint(f\"Time window: 0 to {time_window} seconds\")\nprint(f\"Kinetics samples: {len(kinetics_window)}\")\nprint(f\"Force plates: Left (Fz_L) and Right (Fz_R)\")\nprint()\nprint(\"Ready for interactive gait event annotation!\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation session\n",
    "annotator = create_demo_annotation_session(\n",
    "    trial_id=\"T5\",\n",
    "    data_dir=\"../data\",\n",
    "    output_dir=\"../output\"\n",
    ")\n",
    "\n",
    "print(\"Annotation session initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load T5 trial data\n",
    "annotator.load_trial(\"T5\")\n",
    "\n",
    "# Display data summary\n",
    "print(\"\\nData loaded and synchronized!\")\n",
    "print(f\"Trial duration: {annotator.synchronized_data['kinetics']['time'].max():.1f} seconds\")\n",
    "print(f\"Sampling rate: 1000 Hz\")\n",
    "print(f\"Available modalities: {list(annotator.synchronized_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Annotation Interface\n",
    "\n",
    "### Event Types to Annotate:\n",
    "1. **Left Heel Strike** - Initial contact of left foot (constrained leg)\n",
    "2. **Left Toe Off** - Left foot leaves ground (minimal due to constraint)\n",
    "3. **Right Heel Strike** - Initial contact of right foot (compensating leg)\n",
    "4. **Right Toe Off** - Right foot leaves ground\n",
    "\n",
    "### Annotation Strategy:\n",
    "- Focus on **20-second window** for demo consistency\n",
    "- Use **multi-modal evidence** (force + kinematics + EMG)\n",
    "- Account for **constraint-induced compensation patterns**\n",
    "- Expect **asymmetric patterns** due to left leg limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive annotation interface\n",
    "# This will show a specialized constrained gait view\n",
    "time_range = (0, 20)  # First 20 seconds for demo\n",
    "\n",
    "fig = annotator.create_annotation_interface(\n",
    "    time_range=time_range,\n",
    "    constrained_gait_view=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANNOTATION INTERFACE ACTIVE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nHOW TO ANNOTATE:\")\n",
    "print(\"• Double-click on any plot at the time of a gait event\")\n",
    "print(\"• When prompted, select event type:\")\n",
    "print(\"  1 = Left Heel Strike\")\n",
    "print(\"  2 = Left Toe Off\")\n",
    "print(\"  3 = Right Heel Strike\")\n",
    "print(\"  4 = Right Toe Off\")\n",
    "print(\"  0 = Cancel\")\n",
    "print(\"\\nLOOK FOR:\")\n",
    "print(\"• Force spikes = heel strikes\")\n",
    "print(\"• Force drops = toe offs\")\n",
    "print(\"• Kinematic minima/maxima = foot contact/lift\")\n",
    "print(\"• EMG activation patterns\")\n",
    "print(\"\\nEXPECTED PATTERNS:\")\n",
    "print(\"• Right leg shows normal gait patterns\")\n",
    "print(\"• Left leg shows minimal/altered patterns due to constraint\")\n",
    "print(\"• ~20-25 events total over 20 seconds\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Annotation Progress Monitoring\n",
    "\n",
    "Run this cell periodically to check annotation progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current annotation status\n",
    "summary = annotator.get_annotation_summary()\n",
    "print(summary)\n",
    "\n",
    "# Get validation results\n",
    "validation = annotator.validate_annotations()\n",
    "print(f\"\\nValidation Status: {validation['status']}\")\n",
    "\n",
    "if validation['status'] == 'incomplete':\n",
    "    print(f\"Missing event types: {validation['missing_event_types']}\")\n",
    "elif validation['status'] == 'valid':\n",
    "    print(\"✓ All event types have been annotated!\")\n",
    "    print(\"Ready to save annotations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Annotations\n",
    "\n",
    "When you've finished annotating events, run this cell to save the ground truth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotations to file\n",
    "results = annotator.save_annotations()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANNOTATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nTrial: {results['trial_info']['trial_id']}\")\n",
    "print(f\"Total events annotated: {results['trial_info']['total_events']}\")\n",
    "print(f\"Annotation date: {results['trial_info']['annotation_date']}\")\n",
    "print(f\"Duration: {results['trial_info']['duration_seconds']:.1f} seconds\")\n",
    "\n",
    "if results['events']:\n",
    "    events_df = pd.DataFrame(results['events'])\n",
    "    print(\"\\nEvent Distribution:\")\n",
    "    print(events_df['type'].value_counts())\n",
    "    \n",
    "    print(\"\\nTime Range:\")\n",
    "    print(f\"First event: {events_df['time'].min():.2f}s\")\n",
    "    print(f\"Last event: {events_df['time'].max():.2f}s\")\n",
    "    print(f\"Time span: {events_df['time'].max() - events_df['time'].min():.2f}s\")\n",
    "    \n",
    "    # Show first few events as example\n",
    "    print(\"\\nFirst 5 events:\")\n",
    "    print(events_df[['time', 'type']].head().to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n⚠ No events were annotated!\")\n",
    "    print(\"Please return to the annotation interface and add some events.\")\n",
    "\n",
    "print(f\"\\n✓ Annotations saved to: ../output/T5_ground_truth_events.json\")\n",
    "print(\"This file can now be used for algorithm validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quality Check and Export Preview\n",
    "\n",
    "Final validation of annotation quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display saved annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_file = Path(\"../output/T5_ground_truth_events.json\")\n",
    "\n",
    "if output_file.exists():\n",
    "    with open(output_file, 'r') as f:\n",
    "        saved_data = json.load(f)\n",
    "    \n",
    "    print(\"Ground Truth Annotation Export\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Display metadata\n",
    "    trial_info = saved_data['trial_info']\n",
    "    methodology = saved_data['methodology']\n",
    "    \n",
    "    print(f\"Trial ID: {trial_info['trial_id']}\")\n",
    "    print(f\"Events: {trial_info['total_events']}\")\n",
    "    print(f\"Duration: {trial_info['duration_seconds']}s\")\n",
    "    print(f\"Method: {methodology['annotation_method']}\")\n",
    "    print(f\"Constraint: {methodology['constraint_type']}\")\n",
    "    print(f\"Modalities: {', '.join(methodology['data_modalities'])}\")\n",
    "    \n",
    "    # Event summary\n",
    "    if saved_data['events']:\n",
    "        events_df = pd.DataFrame(saved_data['events'])\n",
    "        \n",
    "        print(\"\\nEvent Summary:\")\n",
    "        for event_type in events_df['type'].unique():\n",
    "            count = len(events_df[events_df['type'] == event_type])\n",
    "            print(f\"  {event_type}: {count} events\")\n",
    "        \n",
    "        # Calculate basic gait metrics\n",
    "        left_hs = events_df[events_df['type'] == 'left_heel_strike']['time'].values\n",
    "        right_hs = events_df[events_df['type'] == 'right_heel_strike']['time'].values\n",
    "        \n",
    "        if len(left_hs) > 1:\n",
    "            left_step_time = np.mean(np.diff(left_hs))\n",
    "            print(f\"\\nLeft step time: {left_step_time:.2f}s\")\n",
    "        \n",
    "        if len(right_hs) > 1:\n",
    "            right_step_time = np.mean(np.diff(right_hs))\n",
    "            print(f\"Right step time: {right_step_time:.2f}s\")\n",
    "            \n",
    "        if len(left_hs) > 1 and len(right_hs) > 1:\n",
    "            asymmetry = abs(left_step_time - right_step_time) / np.mean([left_step_time, right_step_time]) * 100\n",
    "            print(f\"Step time asymmetry: {asymmetry:.1f}%\")\n",
    "    \n",
    "    print(\"\\n✓ Ground truth annotation complete and validated!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Use this ground truth for algorithm validation\")\n",
    "    print(\"2. Compare Traditional/Basic Fusion/AI Fusion accuracy\")\n",
    "    print(\"3. Proceed to notebook 03_validation.ipynb\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No annotation file found.\")\n",
    "    print(\"Please complete the annotation process first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Complete!\n",
    "\n",
    "You have successfully created a sensor-independent ground truth dataset for gait event detection validation.\n",
    "\n",
    "### What you've accomplished:\n",
    "1. ✅ Loaded and synchronized multi-modal T5 trial data\n",
    "2. ✅ Manually annotated gait events using expert biomechanical knowledge\n",
    "3. ✅ Accounted for constrained gait compensation patterns\n",
    "4. ✅ Created reference standard independent of sensor thresholds\n",
    "5. ✅ Exported annotations in format compatible with algorithm validation\n",
    "\n",
    "### Next Steps:\n",
    "- **Proceed to `03_validation.ipynb`** to compare algorithm performance\n",
    "- **Validate accuracy claims**: Traditional (60%) → Basic Fusion (75%) → AI Fusion (92%)\n",
    "- **Generate accuracy progression visualization** for demo\n",
    "\n",
    "This ground truth data will enable scientifically rigorous validation of the multi-sensor fusion demo algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}